---
title: "Class 8: Mini Project"
author: "Chantal Rabay A14528642"
date: "2/14/2022"
output: pdf_document
---

## Preparing the Data

```{r}
r = getOption("repos")
r["CRAN"] = "http://cran.us.r-project.org"
options(repos = r)

# Save your input data file into your Project directory
fna.data <- "WisconsinCancer.csv"

# Complete the following code to input the data and store as wisc.df
wisc.df <- read.csv(fna.data, row.names=1)
```

Checking that my dataframe was uploading correctly.

> use the head() function to see the first 6 rows of the dataframe

```{r}
head(wisc.df)
```
We will not be using the column labelled 'Diagnosis'
```{r}
# We can use -1 here to remove the first column
wisc.data <- wisc.df[,-1]
```

>> Create diagnosis vector for later 

```{r}
diagnosis <- as.numeric(wisc.df$diagnosis =="M")
```

# Exploratory Data Analysis
### [Q1] How many observations are in this data set?

```{r}
# Use nrow() to get the number of rows. This is the number of observations in the data set.
nrow(wisc.data)
```
There are 569 observations.
### [Q2] How many of the observations have a malignant diagnosis?

```{r}
# Use grep() to find all rows in the diagnosis column with "M"
malignant <- grep("M", wisc.df$diagnosis)
# find the length of this vector to know how many rows
length(malignant)
```
There are 212 observations with a malignant diagnosis.

### [Q3] How many variables/features in the data are suffixed with _mean?

```{r}
wisc_col_mean <- wisc.data[,grepl("_mean",colnames(wisc.data))]
ncol(wisc_col_mean)
```
There are 10 variables/features in the data suffixed with _mean.

# Principal Component Analysis 
## Performing PCA

```{r}
# Check column means and standard deviations
colMeans(wisc.data)

apply(wisc.data,2,sd)
```

```{r}
# Perform PCA on wisc.data by completing the following code
install.packages("dplyr")
library("dplyr")
wisc.data2 <- dplyr :: select(wisc.data, -c(X))
wisc.pr <- prcomp(na.omit(wisc.data2),  center = TRUE, scale. = TRUE)

summary(wisc.pr)

```

### [Q4] From your results, what proportion of the original variance is captured by the first principal components (PC1)?
44.27% of the original variance is captured by the first principal components.

### [Q5] How many principal components (PCs) are required to describe at least 70% of the original variance in the data?
Three. PC1-PC3 describe 72.63% of the original variance in the data.

### [Q6] How many principal components (PCs) are required to describe at least 90% of the original variance in the data?
Five. PC1-PC5 describe 91.01% of the original variance in the data. 
```{r}
#Adding Proportion of Variance of PC1-PC5
0.4427+0.1897+0.09393+0.06602+0.05496+0.04025+0.02251
```

## Interpreting PCA Results
```{r}
biplot(wisc.pr)
```
### [Q7] What stands out to you about this plot? Is it easy or difficult to understand? Why?
This plot is very difficult to read due to the density of the samples and size of the labels.Additionally, it is impossible to tell which labels are being assigned where.

```{r}
# Scatter plot observations by components 1 and 2
plot(wisc.pr$x[, c(1, 2)], col = (diagnosis + 1), 
     xlab = "PC1", ylab = "PC2")

```
```{r}
# Repeat for components 1 and 3
plot(wisc.pr$x[, c(1,3) ], col = (diagnosis + 1), 
     xlab = "PC1", ylab = "PC3")
```
### [Q8] Generate a similar plot for principal components 1 and 3. What do you notice about these plots?

The plot comparing components 1 and 2 have less overlapping than the plots comparing 1 and 3. This is because principal component 2 explains more of the variance in the data than principle component 3. 

```{r}
# Create a data.frame for ggplot
df <- as.data.frame(wisc.pr$x)
df$diagnosis <- diagnosis

# Load the ggplot2 package
library(ggplot2)

# Make a scatter plot colored by diagnosis
ggplot(df) + 
  aes(PC1, PC2, col = as.factor(diagnosis)) + 
  geom_point() +
  labs(color="Diagnosis\n") +
  scale_color_hue(labels=c("B","M"))
```
## Variance Explained

```{r}
# Calculate variance of each component
pr.var <- wisc.pr$sdev^2
head(pr.var)
```

```{r}
# Variance explained by each principal component: pve
pve <- pr.var / sum(pr.var)

# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

```{r}
# Alternative scree plot of the same data, note data driven y-axis
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

## Communicating PCA Results

### [Q9] For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?
```{r}
wisc.pr$rotation[,1]
```

Concave.points_mean is -0.26085376

### [Q10] What is the minimum number of principal components required to explain 80% of the variance of the data?
Five principal components is the minimum number required to explain 80% of the variance of the data.

# Hierarchical Clustering

```{r}
# Scale the wisc.data data using the "scale()" function
data.scaled <- scale(wisc.data)
```

```{r}
# Calculating the euclidean distance
data.dist <- dist(data.scaled, method= 'euclidean')
```

```{r}
# Create a hierarchical clustering model
wisc.hclust <- hclust(data.dist, method = 'complete')

```

## Results of Hierarchical Clustering

### [Q11] Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

```{r}
plot(wisc.hclust) 
abline(h = 20, col="red", lty=2)
```
At height 20 the model has 4 clusters.

## Selecting Number of Clusters

```{r}
# Cut tree so that it has 4 clusters: wisc.hclust.clusters
wisc.hclust.clusters <- cutree(wisc.hclust, k = 4)
```

```{r}
table(wisc.hclust.clusters, diagnosis)
```

> Exploring different clusters

```{r}
wisc.hclust.clusters2 <- cutree(wisc.hclust, k = 8)
```

```{r}
table(wisc.hclust.clusters2, diagnosis)
```
A cluster of 8 further breaks up the malignant diagnosis. Other clusters have little effect on separating the different diagnoses

## Using Different Methods

```{r}
wisc.single <- hclust(data.dist, method = 'single')
plot(wisc.single) 
abline(h = 20, col="red", lty=2)
```

```{r}
wisc.average <- hclust(data.dist, method = 'average')
plot(wisc.average) 
abline(h = 20, col="red", lty=2)
```


```{r}
wisc.pr.hclust <- hclust(data.dist, method = 'ward.D2')
plot(wisc.pr.hclust) 
```


### [Q13] Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.
My favorite method for this data set was the 'Complete' method used originally. The dendrogram is most easy and visually pleasing to read, and the clustering is very clear.


# Combining Methods
## Clustering on PCA Results

```{r}
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)
```

```{r}
table(grps, diagnosis)
```

```{r}
plot(wisc.pr$x[,1:2], col=grps)
```

```{r}
plot(wisc.pr$x[,1:2], col=(diagnosis+1))
```
```{r}
g <- as.factor(grps)
levels(g)
```

```{r}
g <- relevel(g,2)
levels(g)
```

```{r}
# Plot using our re-ordered factor 
plot(wisc.pr$x[,1:2], col=g)
```
```{r}
## Use the distance along the first 7 PCs for clustering i.e. wisc.pr$x[, 1:7]
wisc.pr.hclust <- hclust(dist(wisc.pr$x[, 1:7]), method = "ward.D2")
```
```{r}
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=2)
```

### [Q15] How well does the newly created model with four clusters separate out the two diagnoses?
```{r}
# Compare to actual diagnoses
table(wisc.pr.hclust.clusters, diagnosis)
```


### [Q16] How well do the k-means and hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.km$cluster and wisc.hclust.clusters) with the vector containing the actual diagnoses.
```{r}
table(wisc.hclust.clusters, diagnosis)
```

# Prediction 
```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

```{r}
plot(wisc.pr$x[,1:2], col=g)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")

```
### [Q18] Which of these new patients should we prioritize for follow up based on your results?
Patient 2 which has been predicted to have a malignant sample.
